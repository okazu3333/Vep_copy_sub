#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import json
import time
from transformers import pipeline
import torch

class PureNLPSegmentAnalyzer:
    def __init__(self):
        """ç´”ç²‹NLP + æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°åˆ†æå™¨"""
        print("ğŸ¤– ç´”ç²‹NLPãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...", file=sys.stderr)
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        self.sentiment_analyzer = pipeline(
            'sentiment-analysis', 
            model='cl-tohoku/bert-base-japanese-v3'
        )
        
        # æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå®šç¾©
        self.existing_segments = {
            'complaint-urgent': 'ã‚¯ãƒ¬ãƒ¼ãƒ ãƒ»è‹¦æƒ…ç³»',
            'follow-up-dissatisfaction': 'å‚¬ä¿ƒãƒ»æœªå¯¾å¿œã®ä¸æº€',
            'internal-crisis-report': 'ç¤¾å†…å‘ã‘å±æ©Ÿé€šå ±',
            'contract-negotiation': 'å¥‘ç´„ãƒ»å•†è«‡',
            'sales-process': 'å–¶æ¥­ãƒ—ãƒ­ã‚»ã‚¹',
            'customer-support': 'é¡§å®¢ã‚µãƒãƒ¼ãƒˆ'
        }
        
        print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†ï¼", file=sys.stderr)
    
    def map_to_existing_segments(self, sentiment, confidence, text):
        """æ„Ÿæƒ…åˆ†æçµæœã‚’æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
        
        # æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã¨åŒã˜ï¼‰
        if sentiment == 'negative':
            if confidence > 0.8:
                segment_id = 'complaint-urgent'
                segment_name = 'ã‚¯ãƒ¬ãƒ¼ãƒ ãƒ»è‹¦æƒ…ç³»'
                reason = 'é«˜ä¿¡é ¼åº¦negativeæ„Ÿæƒ…'
            else:
                segment_id = 'follow-up-dissatisfaction'
                segment_name = 'å‚¬ä¿ƒãƒ»æœªå¯¾å¿œã®ä¸æº€'
                reason = 'negativeæ„Ÿæƒ…'
        elif sentiment == 'positive':
            if confidence > 0.7:
                segment_id = 'contract-negotiation'
                segment_name = 'å¥‘ç´„ãƒ»å•†è«‡'
                reason = 'é«˜ä¿¡é ¼åº¦positiveæ„Ÿæƒ…'
            else:
                segment_id = 'customer-support'
                segment_name = 'é¡§å®¢ã‚µãƒãƒ¼ãƒˆ'
                reason = 'positiveæ„Ÿæƒ…'
        else:  # neutral
            segment_id = 'sales-process'
            segment_name = 'å–¶æ¥­ãƒ—ãƒ­ã‚»ã‚¹'
            reason = 'neutralæ„Ÿæƒ…'
        
        return {
            'segment_id': segment_id,
            'segment_name': segment_name,
            'confidence': confidence,
            'reason': reason
        }
    
    def analyze_with_segments(self, texts):
        """ç´”ç²‹NLP + æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã§åˆ†æ"""
        results = []
        
        for i, text in enumerate(texts):
            try:
                # æ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
                nlp_result = self.sentiment_analyzer(text[:512])  # é•·ã•åˆ¶é™
                
                # çµæœã®æ­£è¦åŒ–
                if nlp_result['label'] == 'LABEL_0':
                    sentiment = 'negative'
                elif nlp_result['label'] == 'LABEL_1':
                    sentiment = 'positive'
                else:
                    sentiment = 'neutral'
                
                confidence = nlp_result['score']
                
                # æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
                segment_mapping = self.map_to_existing_segments(sentiment, confidence, text)
                
                result = {
                    'text': text[:100] + '...' if len(text) > 100 else text,
                    'sentiment': sentiment,
                    'sentiment_confidence': confidence,
                    'existing_segment_id': segment_mapping['segment_id'],
                    'existing_segment_name': segment_mapping['segment_name'],
                    'mapping_confidence': segment_mapping['confidence'],
                    'mapping_reason': segment_mapping['reason'],
                    'original_label': nlp_result['label'],
                    'original_score': nlp_result['score']
                }
                
                results.append(result)
                
                if (i + 1) % 10 == 0:
                    print(f"ğŸ“ {i+1}/{len(texts)} ä»¶å‡¦ç†å®Œäº†", file=sys.stderr)
                    
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
                results.append({
                    'text': text[:100] + '...' if len(text) > 100 else text,
                    'sentiment': 'error',
                    'sentiment_confidence': 0,
                    'existing_segment_id': 'customer-support',
                    'existing_segment_name': 'é¡§å®¢ã‚µãƒãƒ¼ãƒˆ',
                    'mapping_confidence': 0,
                    'mapping_reason': 'ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã®ãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ',
                    'error': str(e)
                })
        
        return results
    
    def calculate_statistics(self, results):
        """çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—"""
        # æ„Ÿæƒ…åˆ¥ä»¶æ•°
        sentiment_counts = {}
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ä»¶æ•°
        segment_counts = {}
        
        # ä¿¡é ¼åº¦åˆ†å¸ƒ
        confidence_ranges = {'0.0-0.5': 0, '0.5-0.7': 0, '0.7-0.9': 0, '0.9-1.0': 0}
        
        for result in results:
            # æ„Ÿæƒ…åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            sentiment = result['sentiment']
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            segment_name = result['existing_segment_name']
            segment_counts[segment_name] = segment_counts.get(segment_name, 0) + 1
            
            # ä¿¡é ¼åº¦åˆ†å¸ƒ
            if 'sentiment_confidence' in result and isinstance(result['sentiment_confidence'], (int, float)):
                conf = result['sentiment_confidence']
                if conf < 0.5:
                    confidence_ranges['0.0-0.5'] += 1
                elif conf < 0.7:
                    confidence_ranges['0.5-0.7'] += 1
                elif conf < 0.9:
                    confidence_ranges['0.7-0.9'] += 1
                else:
                    confidence_ranges['0.9-1.0'] += 1
        
        return {
            'sentiment_distribution': sentiment_counts,
            'segment_distribution': segment_counts,
            'confidence_distribution': confidence_ranges
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    analyzer = PureNLPSegmentAnalyzer()
    
    # æ¨™æº–å…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿
    texts = []
    input_data = sys.stdin.read()
    
    # JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å€‹åˆ¥ã«åˆ†å‰²
    lines = input_data.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        try:
            data = json.loads(line)
            if 'text' in data:
                texts.append(data['text'])
        except json.JSONDecodeError:
            continue
    
    if not texts:
        print("âŒ ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)
        return
    
    print(f"ğŸ“Š {len(texts)}ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç´”ç²‹NLP + æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã§åˆ†æä¸­...", file=sys.stderr)
    
    # åˆ†æå®Ÿè¡Œ
    results = analyzer.analyze_with_segments(texts)
    
    # çµ±è¨ˆæƒ…å ±è¨ˆç®—
    statistics = analyzer.calculate_statistics(results)
    
    # çµæœçµ±åˆ
    summary = {
        'total_texts': len(texts),
        'statistics': statistics,
        'detailed_results': results
    }
    
    # çµæœå‡ºåŠ›
    print(json.dumps(summary, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main() 