#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import json
import re
import time
from transformers import pipeline
import torch

class ContextAwareAnalyzer:
    def __init__(self):
        """æ–‡è„ˆç†è§£ + ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯åˆ†æå™¨"""
        print("ğŸ¤– æ–‡è„ˆç†è§£ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ä¸­...", file=sys.stderr)
        
        # ç´”ç²‹NLPãƒ¢ãƒ‡ãƒ«ï¼ˆæ–‡è„ˆç†è§£ï¼‰
        self.nlp_analyzer = pipeline(
            'sentiment-analysis', 
            model='cl-tohoku/bert-base-japanese-v3'
        )
        
        # æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå®šç¾©
        self.business_segments = {
            'complaint-urgent': 'ã‚¯ãƒ¬ãƒ¼ãƒ ãƒ»è‹¦æƒ…ç³»',
            'follow-up-dissatisfaction': 'å‚¬ä¿ƒãƒ»æœªå¯¾å¿œã®ä¸æº€',
            'internal-crisis-report': 'ç¤¾å†…å‘ã‘å±æ©Ÿé€šå ±',
            'contract-negotiation': 'å¥‘ç´„ãƒ»å•†è«‡',
            'sales-process': 'å–¶æ¥­ãƒ—ãƒ­ã‚»ã‚¹',
            'customer-support': 'é¡§å®¢ã‚µãƒãƒ¼ãƒˆ'
        }
        
        print("âœ… æ–‡è„ˆç†è§£ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–å®Œäº†ï¼", file=sys.stderr)
    
    def detect_context_flags(self, text):
        """æ–‡è„ˆãƒ•ãƒ©ã‚°ã®æ¤œå‡º"""
        context_flags = {
            'has_negation': False,
            'has_conditional': False,
            'has_comparison': False,
            'has_business_context': False,
            'has_urgency': False,
            'has_positive_context': False
        }
        
        # å¦å®šæ–‡ã®æ¤œå‡º
        negation_patterns = [
            r'å•é¡Œã‚ã‚Šã¾ã›ã‚“',
            r'æ‚ªãã‚ã‚Šã¾ã›ã‚“',
            r'å›°ã‚Šã¾ã›ã‚“',
            r'ä¸æº€ã‚ã‚Šã¾ã›ã‚“',
            r'æ–‡å¥ã‚ã‚Šã¾ã›ã‚“',
            r'ç‰¹ã«å•é¡Œã‚ã‚Šã¾ã›ã‚“',
            r'å…¨ãå•é¡Œã‚ã‚Šã¾ã›ã‚“',
            r'ä½•ã‚‚å•é¡Œã‚ã‚Šã¾ã›ã‚“'
        ]
        
        for pattern in negation_patterns:
            if re.search(pattern, text):
                context_flags['has_negation'] = True
                break
        
        # æ¡ä»¶æ–‡ã®æ¤œå‡º
        conditional_patterns = [
            r'ã‚‚ã—',
            r'å ´åˆ',
            r'ä»®ã«',
            r'æ¡ä»¶',
            r'ã€œã§ã‚ã‚Œã°',
            r'ã€œã®å ´åˆ'
        ]
        
        for pattern in conditional_patterns:
            if re.search(pattern, text):
                context_flags['has_conditional'] = True
                break
        
        # æ¯”è¼ƒæ–‡ã®æ¤œå‡º
        comparison_patterns = [
            r'ã‚ˆã‚Š',
            r'æ¯”è¼ƒçš„',
            r'ç›¸å¯¾çš„ã«',
            r'ã€œã‚ˆã‚Šã‚‚',
            r'ã€œã¨æ¯”ã¹ã¦'
        ]
        
        for pattern in comparison_patterns:
            if re.search(pattern, text):
                context_flags['has_comparison'] = True
                break
        
        # ç·Šæ€¥æ€§ã®æ¤œå‡º
        urgency_patterns = [
            r'ç·Šæ€¥',
            r'è‡³æ€¥',
            r'æ€¥ã',
            r'æ—©æ€¥',
            r'ã™ã',
            r'ä»Šã™ã',
            r'æœŸé™',
            r'ç· åˆ‡',
            r'ç´æœŸ',
            r'é–“ã«åˆã‚ãªã„',
            r'é…ã‚Œã‚‹'
        ]
        
        for pattern in urgency_patterns:
            if re.search(pattern, text):
                context_flags['has_urgency'] = True
                break
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–æ–‡è„ˆã®æ¤œå‡º
        positive_patterns = [
            r'è‰¯ã„',
            r'å„ªç§€',
            r'æº€è¶³',
            r'å–œã³',
            r'å¬‰ã—ã„',
            r'æ¥½ã—ã„',
            r'æœŸå¾…',
            r'å¸Œæœ›',
            r'æˆåŠŸ',
            r'é”æˆ',
            r'å®Œäº†',
            r'æ‰¿çŸ¥',
            r'äº†è§£',
            r'æ‰¿è«¾',
            r'æ‰¿èª'
        ]
        
        for pattern in positive_patterns:
            if re.search(pattern, text):
                context_flags['has_positive_context'] = True
                break
        
        # ãƒ“ã‚¸ãƒã‚¹æ–‡è„ˆã®æ¤œå‡º
        business_patterns = [
            r'è¦‹ç©',
            r'å¥‘ç´„',
            r'å•†è«‡',
            r'å–¶æ¥­',
            r'ææ¡ˆ',
            r'æ‰“ã¡åˆã‚ã›',
            r'ä¼šè­°',
            r'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ',
            r'ç´æœŸ',
            r'å“è³ª',
            r'ã‚µãƒ¼ãƒ“ã‚¹',
            r'ã‚µãƒãƒ¼ãƒˆ'
        ]
        
        for pattern in business_patterns:
            if re.search(pattern, text):
                context_flags['has_business_context'] = True
                break
        
        return context_flags
    
    def adjust_sentiment_by_context(self, nlp_result, context_flags):
        """æ–‡è„ˆã«åŸºã¥ãæ„Ÿæƒ…ã®èª¿æ•´"""
        
        # åŸºæœ¬æ„Ÿæƒ…ã®å–å¾—
        if isinstance(nlp_result, list) and len(nlp_result) > 0:
            first_result = nlp_result[0]
            base_sentiment = first_result['label']
            base_confidence = first_result['score']
        else:
            base_sentiment = 'LABEL_0'
            base_confidence = 0.5
        
        # æ„Ÿæƒ…ã®æ­£è¦åŒ–
        if base_sentiment == 'LABEL_0':
            sentiment = 'negative'
        elif base_sentiment == 'LABEL_1':
            sentiment = 'positive'
        else:
            sentiment = 'neutral'
        
        # æ–‡è„ˆã«ã‚ˆã‚‹èª¿æ•´
        adjusted_sentiment = sentiment
        adjustment_reason = "åŸºæœ¬åˆ¤å®š"
        
        # å¦å®šæ–‡ã®å ´åˆã¯æ„Ÿæƒ…ã‚’åè»¢
        if context_flags['has_negation']:
            if sentiment == 'negative':
                adjusted_sentiment = 'positive'
                adjustment_reason = "å¦å®šæ–‡ã«ã‚ˆã‚‹æ„Ÿæƒ…åè»¢"
            elif sentiment == 'positive':
                adjusted_sentiment = 'negative'
                adjustment_reason = "å¦å®šæ–‡ã«ã‚ˆã‚‹æ„Ÿæƒ…åè»¢"
        
        # æ¡ä»¶æ–‡ã®å ´åˆã¯å–¶æ¥­ç³»ã«èª¿æ•´
        if context_flags['has_conditional'] and sentiment == 'neutral':
            adjusted_sentiment = 'positive'
            adjustment_reason = "æ¡ä»¶æ–‡ã«ã‚ˆã‚‹å–¶æ¥­ç³»åˆ¤å®š"
        
        # ç·Šæ€¥æ€§ã®å ´åˆã¯å±æ©Ÿé€šå ±ç³»ã«èª¿æ•´
        if context_flags['has_urgency'] and sentiment == 'negative':
            adjusted_sentiment = 'strong_negative'
            adjustment_reason = "ç·Šæ€¥æ€§ã«ã‚ˆã‚‹å±æ©Ÿé€šå ±ç³»åˆ¤å®š"
        
        # ä¿¡é ¼åº¦ã®èª¿æ•´
        adjusted_confidence = base_confidence
        
        # æ–‡è„ˆãƒ•ãƒ©ã‚°ãŒå¤šã„ã»ã©ä¿¡é ¼åº¦ã‚’ä¸Šã’ã‚‹
        flag_count = sum(context_flags.values())
        if flag_count > 0:
            adjusted_confidence = min(adjusted_confidence + (flag_count * 0.1), 0.95)
        
        return {
            'original_sentiment': sentiment,
            'adjusted_sentiment': adjusted_sentiment,
            'confidence': adjusted_confidence,
            'adjustment_reason': adjustment_reason,
            'context_flags': context_flags
        }
    
    def map_to_business_segments(self, adjusted_result):
        """ãƒ“ã‚¸ãƒã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°"""
        
        sentiment = adjusted_result['adjusted_sentiment']
        confidence = adjusted_result['confidence']
        context_flags = adjusted_result['context_flags']
        
        # ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã«ã‚ˆã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¤å®š
        if sentiment == 'strong_negative':
            if context_flags['has_urgency']:
                segment_id = 'internal-crisis-report'
                segment_name = 'ç¤¾å†…å‘ã‘å±æ©Ÿé€šå ±'
                reason = 'strong_negativeæ„Ÿæƒ… + ç·Šæ€¥æ€§'
            else:
                segment_id = 'complaint-urgent'
                segment_name = 'ã‚¯ãƒ¬ãƒ¼ãƒ ãƒ»è‹¦æƒ…ç³»'
                reason = 'strong_negativeæ„Ÿæƒ…'
        
        elif sentiment == 'negative':
            if context_flags['has_urgency']:
                segment_id = 'internal-crisis-report'
                segment_name = 'ç¤¾å†…å‘ã‘å±æ©Ÿé€šå ±'
                reason = 'negativeæ„Ÿæƒ… + ç·Šæ€¥æ€§'
            elif context_flags['has_negation']:
                segment_id = 'customer-support'
                segment_name = 'é¡§å®¢ã‚µãƒãƒ¼ãƒˆ'
                reason = 'negativeæ„Ÿæƒ… + å¦å®šæ–‡ï¼ˆå®Ÿéš›ã¯ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰'
            else:
                segment_id = 'follow-up-dissatisfaction'
                segment_name = 'å‚¬ä¿ƒãƒ»æœªå¯¾å¿œã®ä¸æº€'
                reason = 'negativeæ„Ÿæƒ…'
        
        elif sentiment == 'positive':
            if context_flags['has_conditional']:
                segment_id = 'contract-negotiation'
                segment_name = 'å¥‘ç´„ãƒ»å•†è«‡'
                reason = 'positiveæ„Ÿæƒ… + æ¡ä»¶æ–‡'
            elif context_flags['has_business_context']:
                segment_id = 'sales-process'
                segment_name = 'å–¶æ¥­ãƒ—ãƒ­ã‚»ã‚¹'
                reason = 'positiveæ„Ÿæƒ… + ãƒ“ã‚¸ãƒã‚¹æ–‡è„ˆ'
            else:
                segment_id = 'customer-support'
                segment_name = 'é¡§å®¢ã‚µãƒãƒ¼ãƒˆ'
                reason = 'positiveæ„Ÿæƒ…'
        
        else:  # neutral
            if context_flags['has_business_context']:
                segment_id = 'sales-process'
                segment_name = 'å–¶æ¥­ãƒ—ãƒ­ã‚»ã‚¹'
                reason = 'neutralæ„Ÿæƒ… + ãƒ“ã‚¸ãƒã‚¹æ–‡è„ˆ'
            else:
                segment_id = 'customer-support'
                segment_name = 'é¡§å®¢ã‚µãƒãƒ¼ãƒˆ'
                reason = 'neutralæ„Ÿæƒ…'
        
        return {
            'segment_id': segment_id,
            'segment_name': segment_name,
            'confidence': confidence,
            'reason': reason,
            'business_logic': True
        }
    
    def analyze_with_context_and_business_logic(self, text):
        """æ–‡è„ˆç†è§£ + ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã«ã‚ˆã‚‹åˆ†æ"""
        start_time = time.time()
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
            processed_text = text[:512] if len(text) > 512 else text
            
            # 1. ç´”ç²‹NLPã§åŸºæœ¬æ„Ÿæƒ…åˆ¤å®š
            nlp_result = self.nlp_analyzer(processed_text)
            
            # 2. æ–‡è„ˆãƒ•ãƒ©ã‚°ã®æ¤œå‡º
            context_flags = self.detect_context_flags(processed_text)
            
            # 3. æ–‡è„ˆã«åŸºã¥ãæ„Ÿæƒ…èª¿æ•´
            adjusted_result = self.adjust_sentiment_by_context(nlp_result, context_flags)
            
            # 4. ãƒ“ã‚¸ãƒã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
            segment_mapping = self.map_to_business_segments(adjusted_result)
            
            # 5. å‡¦ç†æ™‚é–“è¨ˆç®—
            processing_time = (time.time() - start_time) * 1000
            
            # 6. çµæœçµ±åˆ
            result = {
                'text': text[:100] + '...' if len(text) > 100 else text,
                'original_nlp_result': nlp_result,
                'context_flags': context_flags,
                'sentiment_analysis': adjusted_result,
                'business_segment': segment_mapping,
                'text_length': len(text),
                'processed_text_length': len(processed_text),
                'processing_time_ms': int(processing_time),
                'processed': True,
                'model_version': 'cl-tohoku/bert-base-japanese-v3-context-aware',
                'timestamp': time.time(),
                'analysis_method': 'context_aware_business_logic'
            }
            
            return result
            
        except Exception as e:
            return {
                'error': str(e),
                'processed': False,
                'processing_time_ms': int((time.time() - start_time) * 1000)
            }
    
    def analyze_batch(self, texts):
        """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®ä¸€æ‹¬åˆ†æ"""
        results = []
        
        for i, text in enumerate(texts):
            print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ {i+1}/{len(texts)} ã‚’æ–‡è„ˆç†è§£ + ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã§åˆ†æä¸­...", file=sys.stderr)
            
            result = self.analyze_with_context_and_business_logic(text)
            results.append(result)
            
            if result['processed']:
                sentiment = result['sentiment_analysis']['adjusted_sentiment']
                segment = result['business_segment']['segment_name']
                print(f"âœ… {sentiment} â†’ {segment} ({result['processing_time_ms']}ms)", file=sys.stderr)
            else:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'Unknown error')}", file=sys.stderr)
        
        return results

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    analyzer = ContextAwareAnalyzer()
    
    print("ğŸš€ æ–‡è„ˆç†è§£ + ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯åˆ†æå™¨ãŒèµ·å‹•ã—ã¾ã—ãŸ", file=sys.stderr)
    print("ğŸ“ æ¨™æº–å…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã¾ã™", file=sys.stderr)
    
    # æ¨™æº–å…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿
    texts = []
    input_data = sys.stdin.read()
    
    # JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å€‹åˆ¥ã«åˆ†å‰²
    lines = input_data.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        try:
            data = json.loads(line)
            if 'text' in data:
                texts.append(data['text'])
        except json.JSONDecodeError:
            continue
    
    if not texts:
        print("âŒ ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)
        return
    
    print(f"ğŸ“Š {len(texts)}ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡è„ˆç†è§£ + ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã§åˆ†æä¸­...", file=sys.stderr)
    
    # åˆ†æå®Ÿè¡Œ
    results = analyzer.analyze_batch(texts)
    
    # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
    sentiment_counts = {}
    segment_counts = {}
    
    for result in results:
        if result['processed']:
            sentiment = result['sentiment_analysis']['adjusted_sentiment']
            segment = result['business_segment']['segment_name']
            
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
            segment_counts[segment] = segment_counts.get(segment, 0) + 1
    
    # çµæœçµ±åˆ
    summary = {
        'total_texts': len(texts),
        'statistics': {
            'sentiment_distribution': sentiment_counts,
            'segment_distribution': segment_counts
        },
        'detailed_results': results
    }
    
    # çµæœå‡ºåŠ›
    print(json.dumps(summary, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main() 