#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import json
import time
import re
from transformers import pipeline
import torch

class ImprovedJapaneseSentimentAnalyzer:
    def __init__(self):
        """æ”¹å–„ã•ã‚ŒãŸæ—¥æœ¬èªæ„Ÿæƒ…åˆ†æå™¨ã®åˆæœŸåŒ–"""
        print("ğŸ¤– æ”¹å–„ã•ã‚ŒãŸæ—¥æœ¬èªæ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...", file=sys.stderr)
        
        try:
            # è»½é‡æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            self.sentiment_analyzer = pipeline(
                "sentiment-analysis",
                model="cl-tohoku/bert-base-japanese-v3",
                device=0 if torch.cuda.is_available() else -1
            )
            
            print("âœ… ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†ï¼", file=sys.stderr)
            
            # ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®šç”¨ã®è¾æ›¸
            self.negative_patterns = {
                'å¼·ã„ãƒã‚¬ãƒ†ã‚£ãƒ–': [
                    'æœ€æ‚ª', 'çµ¶æœ›', 'ç ´æ»…', 'å´©å£Š', 'ç ´ç¶»', 'å¤±æ•—', 'å¤§å¤±æ•—',
                    'äºŒåº¦ã¨', 'çµ¶å¯¾ã«', 'æ±ºã—ã¦', 'è¿”é‡‘', 'è§£ç´„', 'ã‚­ãƒ£ãƒ³ã‚»ãƒ«',
                    'æ€’ã‚Š', 'æ¿€æ€’', 'æ†¤ã‚Š', 'æ†ã—ã¿', 'æ¨ã¿', 'å¾©è®'
                ],
                'ä¸­ç¨‹åº¦ãƒã‚¬ãƒ†ã‚£ãƒ–': [
                    'æ‚ªã„', 'è‰¯ããªã„', 'æœŸå¾…å¤–ã‚Œ', 'ãŒã£ã‹ã‚Š', 'å¤±æœ›',
                    'ä¸æº€', 'å•é¡Œ', 'å›°ã£ãŸ', 'å›°ã£ã¦ã„ã¾ã™', 'æ”¹å–„',
                    'å¯¾å¿œ', 'è§£æ±º', 'è¬ç½ª', 'ç”³ã—è¨³', 'ã™ã¿ã¾ã›ã‚“'
                ],
                'è»½å¾®ãƒã‚¬ãƒ†ã‚£ãƒ–': [
                    'æ™®é€š', 'ç‰¹ã«', 'æ€ã‚ãªã„', 'æœŸå¾…ã—ã¦ã„ãŸã»ã©',
                    'å¾®å¦™', 'ã‚¤ãƒã‚¤ãƒ', 'æ™®é€šä»¥ä¸‹', 'å¹³å‡çš„'
                ],
                'ç·Šæ€¥ãƒ»å±æ©Ÿ': [
                    'ç·Šæ€¥', 'è‡³æ€¥', 'æ€¥ã', 'æ—©æ€¥', 'ã™ã', 'ä»Šã™ã',
                    'æœŸé™', 'ç· åˆ‡', 'ç´æœŸ', 'é–“ã«åˆã‚ãªã„', 'é…ã‚Œã‚‹',
                    'ãƒˆãƒ©ãƒ–ãƒ«', 'éšœå®³', 'åœæ­¢', 'ãƒ€ã‚¦ãƒ³', 'ã‚¨ãƒ©ãƒ¼'
                ]
            }
            
            # ãƒã‚¸ãƒ†ã‚£ãƒ–åˆ¤å®šç”¨ã®è¾æ›¸
            self.positive_patterns = {
                'å¼·ã„ãƒã‚¸ãƒ†ã‚£ãƒ–': [
                    'ç´ æ™´ã‚‰ã—ã„', 'å®Œç’§', 'æœ€é«˜', 'æœ€é«˜ç´š', 'æœ€é«˜å“è³ª',
                    'æ„Ÿå‹•', 'æ„Ÿæ¿€', 'æ„Ÿæ¿€', 'æ„Ÿæ¿€', 'æ„Ÿæ¿€',
                    'æ„›ã—ã¦ã‚‹', 'å¤§å¥½ã', 'æœ€é«˜', 'å®Œç’§'
                ],
                'ä¸­ç¨‹åº¦ãƒã‚¸ãƒ†ã‚£ãƒ–': [
                    'è‰¯ã„', 'å„ªç§€', 'æº€è¶³', 'å–œã³', 'å¬‰ã—ã„',
                    'æ¥½ã—ã„', 'æœŸå¾…', 'å¸Œæœ›', 'æˆåŠŸ', 'é”æˆ',
                    'å®Œäº†', 'æ‰¿çŸ¥', 'äº†è§£', 'æ‰¿è«¾', 'æ‰¿èª'
                ],
                'è»½å¾®ãƒã‚¸ãƒ†ã‚£ãƒ–': [
                    'ã¾ã‚ã¾ã‚', 'æ‚ªããªã„', 'æ™®é€šä»¥ä¸Š', 'æœŸå¾…é€šã‚Š',
                    'å®‰å¿ƒ', 'ä¿¡é ¼', 'é ¼ã‚‚ã—ã„', 'å¿ƒå¼·ã„'
                ]
            }
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}", file=sys.stderr)
            raise
    
    def analyze_negative_patterns(self, text):
        """ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ"""
        negative_score = 0
        detected_patterns = []
        
        for category, patterns in self.negative_patterns.items():
            for pattern in patterns:
                if pattern in text:
                    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®é‡ã¿ä»˜ã‘
                    if category == 'å¼·ã„ãƒã‚¬ãƒ†ã‚£ãƒ–':
                        weight = 3.0
                    elif category == 'ä¸­ç¨‹åº¦ãƒã‚¬ãƒ†ã‚£ãƒ–':
                        weight = 2.0
                    elif category == 'è»½å¾®ãƒã‚¬ãƒ†ã‚£ãƒ–':
                        weight = 1.0
                    elif category == 'ç·Šæ€¥ãƒ»å±æ©Ÿ':
                        weight = 2.5
                    else:
                        weight = 1.0
                    
                    negative_score += weight
                    detected_patterns.append({
                        'pattern': pattern,
                        'category': category,
                        'weight': weight
                    })
        
        return negative_score, detected_patterns
    
    def analyze_positive_patterns(self, text):
        """ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ"""
        positive_score = 0
        detected_patterns = []
        
        for category, patterns in self.positive_patterns.items():
            for pattern in patterns:
                if pattern in text:
                    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®é‡ã¿ä»˜ã‘
                    if category == 'å¼·ã„ãƒã‚¸ãƒ†ã‚£ãƒ–':
                        weight = 3.0
                    elif category == 'ä¸­ç¨‹åº¦ãƒã‚¸ãƒ†ã‚£ãƒ–':
                        weight = 2.0
                    elif category == 'è»½å¾®ãƒã‚¸ãƒ†ã‚£ãƒ–':
                        weight = 1.0
                    else:
                        weight = 1.0
                    
                    positive_score += weight
                    detected_patterns.append({
                        'pattern': pattern,
                        'category': category,
                        'weight': weight
                    })
        
        return positive_score, detected_patterns
    
    def determine_sentiment(self, negative_score, positive_score):
        """æ„Ÿæƒ…ã®æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯"""
        total_score = negative_score + positive_score
        
        if total_score == 0:
            return 'neutral', 0.5
        
        # ãƒã‚¬ãƒ†ã‚£ãƒ–åº¦ã®è¨ˆç®—ï¼ˆ0.0ã€œ1.0ï¼‰
        negative_ratio = negative_score / total_score
        
        if negative_ratio > 0.7:
            sentiment = 'strong_negative'
            confidence = min(negative_ratio, 0.95)
        elif negative_ratio > 0.5:
            sentiment = 'negative'
            confidence = negative_ratio
        elif negative_ratio > 0.3:
            sentiment = 'slight_negative'
            confidence = negative_ratio
        elif negative_ratio > 0.1:
            sentiment = 'neutral'
            confidence = 0.5
        else:
            sentiment = 'positive'
            confidence = 1.0 - negative_ratio
        
        return sentiment, confidence
    
    def analyze(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ"""
        start_time = time.time()
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ï¼ˆé•·ã•åˆ¶é™ï¼‰
            processed_text = text[:512] if len(text) > 512 else text
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹åˆ†æ
            negative_score, negative_patterns = self.analyze_negative_patterns(text)
            positive_score, positive_patterns = self.analyze_positive_patterns(text)
            
            # æ„Ÿæƒ…ã®æ±ºå®š
            sentiment, confidence = self.determine_sentiment(negative_score, positive_score)
            
            # å‡¦ç†æ™‚é–“è¨ˆç®—
            processing_time = (time.time() - start_time) * 1000
            
            # çµæœçµ±åˆ
            result = {
                'sentiment': sentiment,
                'sentiment_confidence': round(confidence, 3),
                'negative_score': negative_score,
                'positive_score': positive_score,
                'negative_patterns': negative_patterns,
                'positive_patterns': positive_patterns,
                'text_length': len(text),
                'processed_text_length': len(processed_text),
                'processing_time_ms': int(processing_time),
                'processed': True,
                'model_version': 'cl-tohoku/bert-base-japanese-v3-improved',
                'timestamp': time.time(),
                'analysis_method': 'pattern_based'
            }
            
            return result
            
        except Exception as e:
            return {
                'error': str(e),
                'processed': False,
                'processing_time_ms': int((time.time() - start_time) * 1000)
            }
    
    def analyze_batch(self, texts):
        """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®ä¸€æ‹¬æ„Ÿæƒ…åˆ†æ"""
        results = []
        
        for i, text in enumerate(texts):
            print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ {i+1}/{len(texts)} ã‚’å‡¦ç†ä¸­...", file=sys.stderr)
            result = self.analyze(text)
            results.append(result)
        
        return results

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    analyzer = ImprovedJapaneseSentimentAnalyzer()
    
    print("ğŸš€ æ”¹å–„ã•ã‚ŒãŸæ—¥æœ¬èªæ„Ÿæƒ…åˆ†æå™¨ãŒèµ·å‹•ã—ã¾ã—ãŸ", file=sys.stderr)
    print("ğŸ“ æ¨™æº–å…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã¾ã™", file=sys.stderr)
    
    # æ¨™æº–å…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿
    for line in sys.stdin:
        try:
            data = json.loads(line.strip())
            text = data.get('text', '')
            
            if not text:
                continue
            
            # æ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
            result = analyzer.analyze(text)
            
            # çµæœã‚’æ¨™æº–å‡ºåŠ›ã«å‡ºåŠ›
            print(json.dumps(result, ensure_ascii=False))
            sys.stdout.flush()
            
        except json.JSONDecodeError:
            print("âŒ JSONå½¢å¼ãŒç„¡åŠ¹ã§ã™", file=sys.stderr)
            continue
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™", file=sys.stderr)
            break
        except Exception as e:
            print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            continue

if __name__ == "__main__":
    main() 