#!/usr/bin/env python3
"""
åˆ†æãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèªç”¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿè¡Œæ–¹æ³•:
  python scripts/test_analysis_models.py --test all
  python scripts/test_analysis_models.py --test phase_c
  python scripts/test_analysis_models.py --test phase_d
  python scripts/test_analysis_models.py --test detection_rules
"""

from __future__ import annotations

import argparse
import logging
import os
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from scripts.modeling.train_incident_outcomes import IncidentOutcomeTrainer, TrainingConfig
from scripts.modeling.score_reply_quality import ReplyQualityScorer, ScoreConfig
from scripts.modeling.build_reply_embeddings import ReplyEmbeddingBuilder, EmbeddingConfig
from scripts.modeling.search_similar_cases import SimilarCaseSearcher, SearchConfig

DEFAULT_DATASET = os.environ.get("SA_ALERTS_DATASET", "viewpers.salesguard_alerts")

logger = logging.getLogger(__name__)


def test_phase_c(config: TrainingConfig) -> bool:
    """ãƒ•ã‚§ãƒ¼ã‚ºC: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆçµæœäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=" * 60)
    logger.info("ãƒ•ã‚§ãƒ¼ã‚ºC: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆçµæœäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ")
    logger.info("=" * 60)

    try:
        trainer = IncidentOutcomeTrainer(config)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ“Š ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ä¸­...")
        df = trainer.load_features()
        logger.info(f"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
        
        if df.empty:
            logger.warning("âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚BigQueryãƒ“ãƒ¥ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return False

        # å­¦ç¿’ãƒ†ã‚¹ãƒˆï¼ˆå°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ï¼‰
        logger.info("ğŸ¤– ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
        metrics = trainer.train(df)
        logger.info(f"âœ… å­¦ç¿’å®Œäº†: ROC-AUC={metrics.get('roc_auc', 'N/A')}, è¡Œæ•°={metrics.get('n_rows', 0)}")

        # æ¨è«–ãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ”® æ¨è«–å®Ÿè¡Œä¸­...")
        predictions = trainer.predict(df.head(10))
        logger.info(f"âœ… {len(predictions)} ä»¶ã®äºˆæ¸¬ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        logger.info(f"   ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬: p_resolved_24h={predictions.iloc[0]['p_resolved_24h']:.3f}")

        return True
    except Exception as e:
        logger.error(f"âŒ ãƒ•ã‚§ãƒ¼ã‚ºCãƒ†ã‚¹ãƒˆå¤±æ•—: {e}", exc_info=True)
        return False


def test_phase_d_scoring(config: ScoreConfig) -> bool:
    """ãƒ•ã‚§ãƒ¼ã‚ºD: è¿”ä¿¡å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=" * 60)
    logger.info("ãƒ•ã‚§ãƒ¼ã‚ºD: è¿”ä¿¡å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ")
    logger.info("=" * 60)

    try:
        scorer = ReplyQualityScorer(config)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ“Š è¿”ä¿¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ä¸­...")
        replies = scorer.load_replies()
        logger.info(f"âœ… {len(replies)} ä»¶ã®è¿”ä¿¡ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
        
        if replies.empty:
            logger.warning("âš ï¸  è¿”ä¿¡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚BigQueryãƒ“ãƒ¥ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return False

        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ“ å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ä¸­...")
        scored = scorer.compute_scores(replies.head(10))
        logger.info(f"âœ… {len(scored)} ä»¶ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã—ãŸ")
        
        if len(scored) > 0:
            sample = scored.iloc[0]
            logger.info(f"   ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚³ã‚¢: score={sample['score']:.1f}, level={sample['level']}")
            logger.info(f"   å†…è¨³: politeness={sample['politeness']:.2f}, specificity={sample['specificity']:.2f}")

        return True
    except Exception as e:
        logger.error(f"âŒ ãƒ•ã‚§ãƒ¼ã‚ºDã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}", exc_info=True)
        return False


def test_phase_d_embeddings(config: EmbeddingConfig) -> bool:
    """ãƒ•ã‚§ãƒ¼ã‚ºD: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("=" * 60)
    logger.info("ãƒ•ã‚§ãƒ¼ã‚ºD: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ")
    logger.info("=" * 60)

    try:
        builder = ReplyEmbeddingBuilder(config)
        
        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ”¢ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
        output_path = builder.run()
        logger.info(f"âœ… åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        vectors_path = config.output_dir / "reply_embeddings.npy"
        meta_path = config.output_dir / "reply_embeddings_meta.parquet"
        
        if vectors_path.exists() and meta_path.exists():
            logger.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {vectors_path} ({vectors_path.stat().st_size} bytes)")
            logger.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {meta_path} ({meta_path.stat().st_size} bytes)")
            return True
        else:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {vectors_path}, {meta_path}")
            return False
    except Exception as e:
        logger.error(f"âŒ ãƒ•ã‚§ãƒ¼ã‚ºDåŸ‹ã‚è¾¼ã¿ç”Ÿæˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}", exc_info=True)
        return False


def test_detection_rules() -> bool:
    """æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆï¼ˆAPIçµŒç”±ï¼‰"""
    logger.info("=" * 60)
    logger.info("æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ")
    logger.info("=" * 60)

    try:
        import requests
        
        base_url = os.environ.get("API_BASE_URL", "http://localhost:3000")
        endpoint = f"{base_url}/api/detection-rules"
        
        logger.info(f"ğŸŒ APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {endpoint}")
        
        # å„ãƒ«ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ãƒ†ã‚¹ãƒˆ
        rules = ['inactivity_72h', 'night_reply_rate', 'sentiment_urgency', 'tone_frequency_drop']
        
        for rule_type in rules:
            logger.info(f"ğŸ“‹ ãƒ«ãƒ¼ãƒ«: {rule_type}")
            try:
                response = requests.get(f"{endpoint}?rule_type={rule_type}&limit=5", timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    logger.info(f"   âœ… {data.get('total', 0)} ä»¶ã®æ¤œçŸ¥çµæœ")
                    if data.get('results'):
                        sample = data['results'][0]
                        logger.info(f"   ã‚µãƒ³ãƒ—ãƒ«: thread_id={sample.get('thread_id')}, score={sample.get('score'):.1f}")
                else:
                    logger.warning(f"   âš ï¸  HTTP {response.status_code}: {response.text}")
            except requests.exceptions.RequestException as e:
                logger.warning(f"   âš ï¸  ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        
        return True
    except ImportError:
        logger.warning("âš ï¸  requests ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚APIãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return True
    except Exception as e:
        logger.error(f"âŒ æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}", exc_info=True)
        return False


def main():
    parser = argparse.ArgumentParser(description="åˆ†æãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ")
    parser.add_argument(
        "--test",
        choices=["all", "phase_c", "phase_d", "detection_rules"],
        default="all",
        help="å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆ",
    )
    parser.add_argument("--project_id", default=os.environ.get("GOOGLE_CLOUD_PROJECT_ID", "viewpers"))
    parser.add_argument("--dataset", default=DEFAULT_DATASET)
    parser.add_argument("--limit", type=int, default=100, help="ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿åˆ¶é™")
    parser.add_argument("--log_level", default="INFO")
    parser.add_argument("--no_write", action="store_true", help="BigQueryã¸ã®æ›¸ãè¾¼ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    args = parser.parse_args()

    logging.basicConfig(
        level=getattr(logging, args.log_level.upper()),
        format="%(asctime)s [%(levelname)s] %(message)s",
    )

    results = {}

    # ãƒ•ã‚§ãƒ¼ã‚ºCãƒ†ã‚¹ãƒˆ
    if args.test in ("all", "phase_c"):
        phase_c_config = TrainingConfig(
            project_id=args.project_id,
            dataset=args.dataset,
            model_version="test",
            write_results=not args.no_write,
            limit=args.limit,
        )
        results["phase_c"] = test_phase_c(phase_c_config)

    # ãƒ•ã‚§ãƒ¼ã‚ºDãƒ†ã‚¹ãƒˆ
    if args.test in ("all", "phase_d"):
        from datetime import datetime
        
        phase_d_scoring_config = ScoreConfig(
            project_id=args.project_id,
            dataset=args.dataset,
            model_version="test",
            write_results=not args.no_write,
            limit=args.limit,
        )
        results["phase_d_scoring"] = test_phase_d_scoring(phase_d_scoring_config)

        from pathlib import Path
        phase_d_embedding_config = EmbeddingConfig(
            project_id=args.project_id,
            model_name="intfloat/multilingual-e5-base",
            dataset=args.dataset,
            output_dir=Path("artifacts/reply_embeddings_test"),
            batch_size=16,
            limit=args.limit,
        )
        results["phase_d_embeddings"] = test_phase_d_embeddings(phase_d_embedding_config)

    # æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ
    if args.test in ("all", "detection_rules"):
        results["detection_rules"] = test_detection_rules()

    # çµæœã‚µãƒãƒª
    logger.info("=" * 60)
    logger.info("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒª")
    logger.info("=" * 60)
    for test_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        logger.info(f"{status}: {test_name}")

    all_passed = all(results.values())
    sys.exit(0 if all_passed else 1)


if __name__ == "__main__":
    main()

