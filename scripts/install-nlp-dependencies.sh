#!/bin/bash

echo "ğŸš€ NLPä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."

# Pythonä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo "ğŸ“¦ Pythonä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
pip3 install --upgrade pip
pip3 install transformers torch spacy sentencepiece

# æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
echo "ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."

# spaCyæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«
python3 -m spacy download ja_core_news_sm

# Transformersè»½é‡æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
echo "ğŸ¤– Transformersãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."
python3 -c "
from transformers import pipeline
print('è»½é‡æ—¥æœ¬èªæ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...')
sentiment_analyzer = pipeline('sentiment-analysis', model='cl-tohoku/bert-base-japanese-v3')
print('âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼')
"

echo "âœ… NLPä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ï¼"
echo "ğŸ“Š ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:"
pip3 list | grep -E "(transformers|torch|spacy|sentencepiece)" 