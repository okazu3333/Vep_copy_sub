import { NextRequest, NextResponse } from 'next/server'
import { JapaneseNLPAnalyzer } from '@/lib/japanese-nlp-analyzer'
import { PatternMatcherV2 } from '@/lib/pattern-matcher-v2'
import { BigQuery } from '@google-cloud/bigquery'
import { PatternMatchResult } from '@/lib/nlp-analyzer-v2'

const japaneseNLPAnalyzer = new JapaneseNLPAnalyzer()
const bigquery = new BigQuery()

export async function POST(request: NextRequest) {
  try {
    const { action, text, limit = 5, saveResults = false } = await request.json()
    
    if (action === 'analyze_single_text') {
      return await analyzeSingleJapaneseText(text)
    } else if (action === 'analyze_bigquery_data') {
      return await analyzeBigQueryJapaneseData(limit, saveResults)
    } else if (action === 'test_translation') {
      return await testTranslation(text)
    } else {
      return NextResponse.json({ 
        success: false, 
        error: 'Invalid action. Use analyze_single_text, analyze_bigquery_data, or test_translation' 
      })
    }
  } catch (error) {
    console.error('âŒ æ—¥æœ¬èªNLPåˆ†æAPIã‚¨ãƒ©ãƒ¼:', error)
    return NextResponse.json({ 
      success: false, 
      error: 'Failed to process Japanese NLP analysis', 
      details: error instanceof Error ? error.message : 'Unknown error' 
    }, { status: 500 })
  }
}

/**
 * å˜ä¸€ã®æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æ
 */
async function analyzeSingleJapaneseText(text: string) {
  console.log('ğŸ” å˜ä¸€æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆåˆ†æé–‹å§‹...')
  
  try {
    // æ—¥æœ¬èªNLPåˆ†æ
    const japaneseResult = await japaneseNLPAnalyzer.analyzeJapaneseText(text)
    
    // ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆç¿»è¨³å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
    let patternMatches: PatternMatchResult[] = []
    if (japaneseResult.translatedText && !japaneseResult.error) {
      try {
        patternMatches = PatternMatcherV2.matchPatterns(
          'ãƒ†ã‚¹ãƒˆä»¶å',
          japaneseResult.translatedText,
          {
            message_id: 'test-message',
            thread_id: 'test-thread',
            subject: 'ãƒ†ã‚¹ãƒˆä»¶å',
            body: japaneseResult.translatedText,
            sentiment: {
              score: japaneseResult.nlpAnalysis.sentiment.score,
              magnitude: japaneseResult.nlpAnalysis.sentiment.magnitude,
              label: japaneseResult.nlpAnalysis.sentiment.score > 0 ? 'POSITIVE' : 
                     japaneseResult.nlpAnalysis.sentiment.score < 0 ? 'NEGATIVE' : 'NEUTRAL'
            },
            entities: japaneseResult.nlpAnalysis.entities,
            categories: japaneseResult.nlpAnalysis.categories,
            syntax: {
              sentences: 1,
              tokens: japaneseResult.nlpAnalysis.syntax.textLength,
              avg_sentence_length: japaneseResult.nlpAnalysis.syntax.textLength
            },
            analysis_timestamp: new Date().toISOString()
          }
        )
      } catch (error) {
        console.warn('âš ï¸ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã‚¨ãƒ©ãƒ¼:', error)
      }
    }
    
    return NextResponse.json({
      success: true,
      analysis_result: {
        ...japaneseResult,
        pattern_matches: patternMatches,
        analysis_timestamp: new Date().toISOString()
      }
    })
  } catch (error) {
    console.error('âŒ å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼:', error)
    return NextResponse.json({
      success: false,
      error: 'Failed to analyze single text',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 })
  }
}

/**
 * BigQueryã®æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ
 */
async function analyzeBigQueryJapaneseData(limit: number, saveResults: boolean) {
  console.log(`ğŸš€ BigQueryæ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿åˆ†æé–‹å§‹: ${limit}ä»¶`)
  
  try {
    // BigQueryã‹ã‚‰æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    const query = `
      SELECT message_id, thread_id, \`from\` as sender_email, subject, body, date
      FROM \`viewpers.salesguard_alerts.alerts_clean_v7_dedup\`
      WHERE (
        body NOT LIKE '$B%' AND body NOT LIKE '%$B%' AND
        body NOT LIKE '%ä»¥ä¸‹ã®ã¨ãŠã‚Šé…ä¿¡ä¾é ¼é€ä¿¡å®Œäº†ã—ã¾ã—ãŸ%' AND
        subject NOT LIKE '%é…ä¿¡ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ é…ä¿¡å®Œäº†å ±å‘Š%' AND
        \`from\` NOT LIKE '%info@%' AND \`from\` NOT LIKE '%noreply@%' AND
        \`from\` NOT LIKE '%support@%' AND \`from\` NOT LIKE '%magazine@%'
      )
      ORDER BY date DESC
      LIMIT ${limit}
    `
    
    console.log('ğŸ“Š BigQueryã‚¯ã‚¨ãƒªå®Ÿè¡Œä¸­...')
    const [rows] = await bigquery.query({ query, useLegacySql: false })
    console.log(`âœ… ${rows.length}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—`)
    
    const analysisResults = []
    let successful = 0
    let failed = 0
    
    for (const row of rows) {
      try {
        console.log(`ğŸ“ ${successful + failed + 1}/${rows.length}ä»¶ç›®ã‚’åˆ†æä¸­...`)
        
        // æ—¥æœ¬èªNLPåˆ†æ
        const japaneseResult = await japaneseNLPAnalyzer.analyzeJapaneseText(row.body)
        
        // ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        let patternMatches: PatternMatchResult[] = []
        if (japaneseResult.translatedText && !japaneseResult.error) {
          try {
            patternMatches = PatternMatcherV2.matchPatterns(
              row.subject || '',
              japaneseResult.translatedText,
              {
                message_id: row.message_id,
                thread_id: row.thread_id,
                subject: row.subject || '',
                body: japaneseResult.translatedText,
                sentiment: {
                  score: japaneseResult.nlpAnalysis.sentiment.score,
                  magnitude: japaneseResult.nlpAnalysis.sentiment.magnitude,
                  label: japaneseResult.nlpAnalysis.sentiment.score > 0 ? 'POSITIVE' : 
                         japaneseResult.nlpAnalysis.sentiment.score < 0 ? 'NEGATIVE' : 'NEUTRAL'
                },
                entities: japaneseResult.nlpAnalysis.entities,
                categories: japaneseResult.nlpAnalysis.categories,
                syntax: {
                  sentences: 1,
                  tokens: japaneseResult.nlpAnalysis.syntax.textLength,
                  avg_sentence_length: japaneseResult.nlpAnalysis.syntax.textLength
                },
                analysis_timestamp: new Date().toISOString()
              }
            )
          } catch (error) {
            console.warn(`âš ï¸ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã‚¨ãƒ©ãƒ¼:`, error)
          }
        }
        
        const result = {
          message_id: row.message_id,
          thread_id: row.thread_id,
          sender_email: row.sender_email,
          subject: row.subject || '',
          body: row.body,
          date: row.date,
          japanese_nlp_analysis: japaneseResult,
          pattern_matches: patternMatches,
          pattern_matches_count: patternMatches.length,
          analysis_timestamp: new Date().toISOString()
        }
        
        analysisResults.push(result)
        successful++
        
        if (successful % 5 === 0) {
          console.log(`âœ… ${successful}/${rows.length}ä»¶å®Œäº†`)
        }
        
      } catch (error) {
        console.error(`âŒ ${successful + failed + 1}ä»¶ç›®ã®åˆ†æã‚¨ãƒ©ãƒ¼:`, error)
        failed++
        
        analysisResults.push({
          message_id: row.message_id,
          thread_id: row.thread_id,
          sender_email: row.sender_email,
          subject: row.subject || '',
          body: row.body,
          date: row.date,
          japanese_nlp_analysis: null,
          pattern_matches: [],
          pattern_matches_count: 0,
          analysis_timestamp: new Date().toISOString(),
          error: error instanceof Error ? error.message : 'Unknown error'
        })
      }
    }
    
    // çµæœã‚’BigQueryã«ä¿å­˜
    if (saveResults && analysisResults.length > 0) {
      try {
        await saveJapaneseNLPAnalysisResults(analysisResults)
        console.log('ğŸ’¾ åˆ†æçµæœã‚’BigQueryã«ä¿å­˜å®Œäº†')
      } catch (error) {
        console.error('âŒ BigQueryä¿å­˜ã‚¨ãƒ©ãƒ¼:', error)
      }
    }
    
    // çµ±è¨ˆæƒ…å ±
    const summary = {
      total_processed: rows.length,
      successful: successful,
      failed: failed,
      success_rate: ((successful / rows.length) * 100).toFixed(2) + '%',
      analysis_timestamp: new Date().toISOString()
    }
    
    console.log('ğŸ¯ BigQueryæ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿åˆ†æå®Œäº†:', summary)
    
    return NextResponse.json({
      success: true,
      summary,
      results: analysisResults.slice(0, 10), // æœ€åˆã®10ä»¶ã®ã¿è¿”ã™
      total_results: analysisResults.length
    })
    
  } catch (error) {
    console.error('âŒ BigQueryæ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼:', error)
    return NextResponse.json({
      success: false,
      error: 'Failed to analyze BigQuery Japanese data',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 })
  }
}

/**
 * ç¿»è¨³æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
 */
async function testTranslation(text: string) {
  console.log('ğŸŒ ç¿»è¨³æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹...')
  
  try {
    const japaneseResult = await japaneseNLPAnalyzer.analyzeJapaneseText(text)
    
    return NextResponse.json({
      success: true,
      test_result: {
        original_text: text,
        translated_text: japaneseResult.translatedText,
        translation_confidence: japaneseResult.translationConfidence,
        nlp_analysis: japaneseResult.nlpAnalysis,
        test_timestamp: new Date().toISOString()
      }
    })
  } catch (error) {
    console.error('âŒ ç¿»è¨³ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼:', error)
    return NextResponse.json({
      success: false,
      error: 'Failed to test translation',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 })
  }
}

/**
 * æ—¥æœ¬èªNLPåˆ†æçµæœã‚’BigQueryã«ä¿å­˜
 */
async function saveJapaneseNLPAnalysisResults(results: any[]) {
  try {
    // æ—¥æœ¬èªNLPåˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    const createTableQuery = `
      CREATE TABLE IF NOT EXISTS \`viewpers.salesguard_alerts.japanese_nlp_analysis_results\` (
        message_id STRING,
        thread_id STRING,
        sender_email STRING,
        subject STRING,
        body STRING,
        date STRING,
        japanese_nlp_analysis STRUCT<
          original_text STRING,
          translated_text STRING,
          translation_confidence FLOAT64,
          nlp_analysis STRUCT<
            sentiment_score FLOAT64,
            sentiment_magnitude FLOAT64,
            entities_count INT64,
            categories_count INT64,
            language STRING,
            text_length INT64
          >,
          error STRING
        >,
        pattern_matches_count INT64,
        analysis_timestamp TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP()
      )
      PARTITION BY DATE(analysis_timestamp)
      CLUSTER BY thread_id, sender_email
    `
    
    await bigquery.query({ query: createTableQuery, useLegacySql: false })
    
    // ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ç”¨ã«æ•´å½¢
    const rows = results.map(result => ({
      message_id: result.message_id,
      thread_id: result.thread_id,
      sender_email: result.sender_email,
      subject: result.subject,
      body: result.body,
      date: result.date,
      japanese_nlp_analysis: {
        original_text: result.japanese_nlp_analysis?.originalText || '',
        translated_text: result.japanese_nlp_analysis?.translatedText || '',
        translation_confidence: result.japanese_nlp_analysis?.translationConfidence || 0,
        nlp_analysis: {
          sentiment_score: result.japanese_nlp_analysis?.nlpAnalysis?.sentiment?.score || 0,
          sentiment_magnitude: result.japanese_nlp_analysis?.nlpAnalysis?.sentiment?.magnitude || 0,
          entities_count: result.japanese_nlp_analysis?.nlpAnalysis?.entities?.length || 0,
          categories_count: result.japanese_nlp_analysis?.nlpAnalysis?.categories?.length || 0,
          language: result.japanese_nlp_analysis?.nlpAnalysis?.syntax?.language || 'unknown',
          text_length: result.japanese_nlp_analysis?.nlpAnalysis?.syntax?.textLength || 0
        },
        error: result.japanese_nlp_analysis?.error || null
      },
      pattern_matches_count: result.pattern_matches_count,
      analysis_timestamp: result.analysis_timestamp
    }))
    
    // BigQueryã«æŒ¿å…¥
    const dataset = bigquery.dataset('salesguard_alerts')
    const table = dataset.table('japanese_nlp_analysis_results')
    
    await table.insert(rows)
    console.log(`ğŸ’¾ ${rows.length}ä»¶ã®æ—¥æœ¬èªNLPåˆ†æçµæœã‚’ä¿å­˜å®Œäº†`)
    
  } catch (error) {
    console.error('âŒ æ—¥æœ¬èªNLPåˆ†æçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼:', error)
    throw error
  }
} 