# 実データ運用可能性評価：セグメント遷移・自動解決機能

## 概要

本ドキュメントでは、実装したセグメント遷移・自動解決機能が実データで運用可能かを評価し、必要な修正点を整理します。

## 実装済み機能

### 1. セグメント遷移機能
- **予兆→発生の自動遷移**: 検知スコア、緊急度、感情スコア、検知ルールに基づく自動判定
- **発生→回復の自動遷移**: 対応状況、鎮火確率、感情スコアに基づく自動判定
- **遷移履歴の記録**: `alert_segment_history`テーブルに記録

### 2. 自動解決機能
- **ポジティブ反応による自動解決**: 感情スコアがポジティブな場合の自動`completed`化
- **解決履歴の記録**: `alert_auto_resolutions`テーブルに記録

## 実データ運用に必要な前提条件

### ✅ 必須テーブル・ビュー

1. **`alerts_v2_scored`テーブル**
   - **必須カラム**:
     - `thread_id` (STRING)
     - `alert_id` または `id` (STRING) - **要確認**
     - `primary_segment` または `primarySegment` (STRING) - **要確認**
     - `status` (STRING: 'unhandled', 'in_progress', 'completed')
     - `detection_score` (FLOAT64)
     - `urgency_score` (FLOAT64)
     - `sentiment_score` (FLOAT64)
     - `updated_at` (TIMESTAMP)
     - `assigned_user_id` (STRING, オプション)

2. **`unified_email_messages`テーブル**
   - **必須カラム**:
     - `thread_id` (STRING)
     - `datetime` (TIMESTAMP)
     - `direction` (STRING: 'inbound', 'outbound')
     - `sentiment_score` (FLOAT64)

3. **依存テーブル（オプション、存在しない場合はNULLで処理）**
   - `incident_outcomes` (Phase Cデータ)
     - `thread_id`, `p_resolved_24h`, `ttr_pred_min`
   - `reply_quality` (Phase Dデータ)
     - `thread_id`, `quality_score`
   - `detection_alerts` (検知ルールデータ)
     - `thread_id`, `rule_type`, `hours_since_last_activity`, `score`

### ⚠️ 実データでの確認が必要な項目

#### 1. カラム名の不一致

**問題**: 実装では`primary_segment`を使用しているが、実際のテーブルが`primarySegment`（キャメルケース）の可能性がある。

**確認方法**:
```sql
-- BigQueryで実行
SELECT column_name, data_type
FROM `viewpers.salesguard_alerts.INFORMATION_SCHEMA.COLUMNS`
WHERE table_name = 'alerts_v2_scored'
  AND column_name LIKE '%segment%'
ORDER BY ordinal_position;
```

**修正が必要な場合**:
- `scripts/sql/bq_alert_transitions.sql`の`primary_segment`を実際のカラム名に修正
- `scripts/process_alert_transitions.ts`のUPDATE文を修正

#### 2. `alert_id`カラムの存在確認

**問題**: 実装では`alert_id`を使用しているが、実際のテーブルが`id`の可能性がある。

**確認方法**:
```sql
-- BigQueryで実行
SELECT column_name, data_type
FROM `viewpers.salesguard_alerts.INFORMATION_SCHEMA.COLUMNS`
WHERE table_name = 'alerts_v2_scored'
  AND (column_name LIKE '%alert%' OR column_name = 'id')
ORDER BY ordinal_position;
```

**修正が必要な場合**:
- `scripts/sql/bq_alert_transitions.sql`の`alert_id`を実際のカラム名に修正
- `scripts/process_alert_transitions.ts`の`alert_id`参照を修正

#### 3. 依存テーブルの存在確認

**確認方法**:
```sql
-- BigQueryで実行
SELECT table_name
FROM `viewpers.salesguard_alerts.INFORMATION_SCHEMA.TABLES`
WHERE table_name IN (
  'incident_outcomes',
  'reply_quality',
  'detection_alerts'
);
```

**対応**:
- 存在しない場合は、ビュー内のLEFT JOINでNULLとして処理されるため、エラーにはならない
- ただし、遷移判定の精度が低下する可能性がある

## 実データ運用前のチェックリスト

### 1. テーブル構造の確認

- [ ] `alerts_v2_scored`テーブルのカラム名を確認
- [ ] `primary_segment` vs `primarySegment`の確認
- [ ] `alert_id` vs `id`の確認
- [ ] `status`カラムの値が`'unhandled'`, `'in_progress'`, `'completed'`であることを確認

### 2. 依存テーブルの確認

- [ ] `unified_email_messages`テーブルの存在確認
- [ ] `incident_outcomes`テーブルの存在確認（オプション）
- [ ] `reply_quality`テーブルの存在確認（オプション）
- [ ] `detection_alerts`テーブルの存在確認（オプション）

### 3. ビューの作成

- [ ] `bq_alert_transitions.sql`を実行してビューを作成
- [ ] `vw_alert_transition_candidates`ビューが正常に作成されることを確認
- [ ] `vw_auto_resolution_candidates`ビューが正常に作成されることを確認

### 4. テスト実行

- [ ] `scripts/process_alert_transitions.ts`を実行してエラーがないことを確認
- [ ] 遷移候補が正しく検出されることを確認
- [ ] 自動解決候補が正しく検出されることを確認
- [ ] 履歴テーブルに正しく記録されることを確認

## 実データ運用時の注意点

### 1. エラーハンドリング

現在の実装では、以下のエラーが発生する可能性があります：

- **カラム名不一致エラー**: `primary_segment`が存在しない場合
- **UPDATE文エラー**: `alerts_v2_scored`テーブルが更新不可の場合
- **履歴テーブル挿入エラー**: `alert_segment_history`テーブルが存在しない場合

**推奨対応**:
- バッチ処理にtry-catchを追加（既に実装済み）
- エラーログを詳細に記録
- 失敗した場合のロールバック機能を検討

### 2. パフォーマンス

- **大量データでの実行時間**: 実データが大量の場合、ビューの実行時間が長くなる可能性
- **UPDATE文の実行時間**: 大量のアラートを更新する場合、時間がかかる可能性

**推奨対応**:
- バッチ処理を定期的に実行（例: 1時間ごと）
- 処理対象を絞り込む（例: 過去24時間以内に更新されたアラートのみ）
- 並列処理を検討

### 3. データ整合性

- **重複遷移の防止**: 同じアラートが複数回遷移しないようにする
- **履歴の整合性**: 遷移履歴とアラートの状態が一致していることを確認

**推奨対応**:
- 遷移前に現在のセグメントを確認
- 履歴テーブルに既に記録されている遷移をスキップ

## リアルタイム検知切替時の想定コスト

### 1. 算定前提
- 監視対象メール: Gmail Users.watch + Pub/Sub + Cloud Run で受信し、`alerts_v2_scored` 相当へ即時反映
- 1イベントあたり 1.2 秒の処理（0.5 vCPU / 0.5 GiB メモリ想定、差分取得とスコアリングの合計）
- BigQuery へストリーミング Insert（Storage Write API）、1レコード 12 KB（メタデータ + スコア + セグメント）
- BigQuery ダッシュボードはオンデマンド課金（$5/TB スキャン前提）
- レート: 1 USD = 150 JPY（参考値。実際は決済レートに依存）

### 2. カテゴリ別コストイメージ（月額）
- **Cloud Run/ワーカー計算**: `イベント数 × 1.2s × (0.5vCPU×$0.000024 + 0.5GiB×$0.0000025)`  
  → 10k件/日で約 $4.8、20万件/日でも $95 程度。処理時間が長いほど線形に増加。
- **Pub/Sub 配信**: $0.40 / 100万メッセージ。冗長通知を含めても主に数ドル以内。
- **BigQuery ストリーミング + ストレージ**: 12KB/件で $0.05/GB（書き込み） + $0.02/GB（月保管）。  
  → 18GB/月（5万件/日）で 約 $1.3（書き込み0.9 + 保管0.36）。
- **BigQuery クエリ**: 集約ビューを活用しても 1〜12TB/月 のスキャンを想定すると $5〜$60 程度。
- **監視/ログ（Cloud Logging, Monitoring, Error Reporting）**: 取込量に応じ $5〜$40/月。ノイズ削減が重要。
- **Secret Manager / Artifact Registry 等の周辺コスト**: 数ドル/月。大半は固定費。

### 3. シナリオ別の概算（月額, VAT/割引抜き）

| モード | 想定イベント数/日 | Cloud Run計算 | Pub/Sub | BQ挿入+保管 | BQクエリ | 監視/その他 | 合計 (USD) | 合計 (JPY) |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| PoC/段階導入 | 10,000 | $4.8 | $0.1 | $0.3 | $5 | $5 | **$15** | **約2,300円** |
| 本番初期 | 50,000 | $23.9 | $0.6 | $1.3 | $20 | $15 | **$61** | **約9,200円** |
| 拡張フェーズ | 200,000 | $95.4 | $2.4 | $5.0 | $60 | $40 | **$203** | **約30,500円** |

> 備考: イベント数は「リアルタイム検知対象メール + セグメント更新トリガー」の合計。Cloud Run の同時実行や BigQuery の前集計が最適化されるとさらに圧縮できます。

### 4. 追加で見込むべきコスト項目
- **初期開発/PoC**: Gmail watch・Pub/Sub 経路・差分ワーカー・BigQuery スキーマ調整で 3〜4 人週 (≈ 120〜160h)。
- **再同期/運用 Runbook**: `historyId` 差分ギャップや DLQ リプレイの自動化に 40〜60h。
- **監査/セキュリティ**: OAuth クライアント、Secret Manager、IAM レビュー、監査ログ保存で 10〜20h。
- **テナント増対応**: 監視対象アカウントが急増する場合、クォータ対策のためプロジェクト分割や別キューを用意する追加開発が必要（都度 1〜2 人週見込み）。

### 5. コスト抑制のヒント
- Pub/Sub 受信は ACK 後に Cloud Tasks / Cloud Workflows へ積み、処理をバッチ化して vCPU 占有時間を圧縮
- BigQuery は取り込みテーブルを日付パーティション + `thread_id` クラスタで絞り、ダッシュボードはマテビューで軽量化
- 添付/大本文は Cloud Storage に後段保管し、BigQuery には要約のみ保存してストレージを削減
- 失敗イベントのリトライは冪等 ID で抑制し、重複書き込みを防ぐ（コスト + データ品質の両面に効く）

## 分析モデル実用化タスク

### 1. 推論クライアント抽象レイヤー設計
- 目的: Hugging Face Inference API 利用と自前ホスティング（GPU/CPU）を任意に切替可能な構造にする。
- 実装計画:
  1. `lib/ai/sentimentClient.ts`（新規）に共通インターフェースを定義。例: `analyzeSentiment(text: string, options): Promise<SentimentResult>`
  2. `providers/huggingface.ts`（APIモード）と `providers/local.ts`（自前推論モード）を実装し、環境変数 `SENTIMENT_PROVIDER=api|local` で切替。
  3. 既存の `app/api/huggingface-sentiment/route.ts` は上記クライアントを呼ぶラッパーに変更し、フォールバック処理（ルールベース）もここで統一管理。
  4. ローカル推論モードは OSS モデル（例: `cl-tohoku/bert-base-japanese-v3`）を FastAPI/Text Generation Inference などでホスティングし、Next.js から HTTP 経由で利用。
  5. 推論結果のスキーマ（`sentiment_score`, `confidence`, `labels[]` など）を `types/ai.ts` に切り出し、`alerts_v2_scored` 更新や UI 表示で共通利用。

### 2. 推論パイプラインと運用フロー
1. **データ取り込み**: Gmail 差分取得 → `unified_email_messages` へ保存 → `alerts_v2_scored` に新規/更新フラグを立てる。
2. **前処理バッチ** (`scripts/process_alert_transitions.ts` 拡張予定):
   - トークナイズ/正規化、本文長の制御、添付テキスト抽出。
   - モデルごとに必要なメタ（`language`, `segment_hint`, `urgency_hint`）を付与。
3. **推論ワーカー**:
   - Cloud Run/Cloud Functions/自前 GPU サービスで常駐。
   - キューは Pub/Sub または BigQuery キュー表で管理し、失敗時は DLQ + 再試行上限 3 回。
4. **結果書き戻し**:
   - `alerts_v2_scored` の `sentiment_score`, `urgency_score`, `ai_summary_source`, `model_version` を更新。
   - 履歴テーブルに推論ログを記録（監査/再学習用）。
5. **監視**:
   - 推論レイテンシ p50/p95、失敗率、プロバイダー切替状況、GPU 利用率を Cloud Monitoring で可視化。
   - `SENTIMENT_PROVIDER` がフォールバック状態になった際にアラートを送出。

### 3. 推論モード比較（運用/コストの観点）
| 項目 | Hugging Face API | 自前ホスティング (GPU) |
| --- | --- | --- |
| 初期実装 | ラッパー実装のみで即利用可 | 推論サーバ構築、監視、デプロイが必要 |
| スケーリング | マネージド、自動 | GPU 追加・オートスケール設計が必要 |
| コスト | 従量課金（リクエスト増で比例） | GPU 常時稼働コスト（高負荷時に有利） |
| セキュリティ | 外部APIに本文送信 | 社内ネットワークで閉じられる |
| カスタマイズ | 事前学習モデル中心 | ファインチューニング/マルチモデル可 |

### 4. UI/UX 実データ仕様への反映
- `app/alerts/page.tsx` / `components/alerts/AlertDetail.tsx`
  - `ai_summary` を「本文プレビュー」と「AI要約（生成元ラベル付）」に分割表示。
  - `sentiment_score`, `urgency_score`, `segment_confidence` など実データ指標をカード/バッジで表示し、閾値は `types/ai.ts` に集約。
  - モデル情報（`model_version`, `provider`) をツールチップで参照可能にして透明性を確保。
- モックデータ (`lib/mock-data.ts`, `data/mock/dummyAlerts.ts`) を実運用レンジ（スコア0〜1、信頼度0〜100% 等）で再生成し、UI の見た目を本番想定に揃える。
- 画面単位の変更案:
  | 画面/コンポーネント | 変更内容 | データソース |
  | --- | --- | --- |
  | `app/alerts/page.tsx` リスト行 | 件名下に「本文プレビュー（最終メール）」、その下に「AI要約 + 生成元バッジ（LLM/Rule/未生成）」を表示。 | `alert.body_preview`, `alert.ai_summary`, `alert.ai_summary_source` |
  | `components/alerts/AlertCard.tsx` | 左列にスコアカード（感情/緊急度/セグメント確信度）を追加し、色分けを `types/ai.ts` の閾値に合わせる。 | `alert.sentiment_score`, `alert.urgency_score`, `alert.segment_confidence` |
  | `components/alerts/AlertDetail.tsx` | 推論メタ情報（モデル名/バージョン/プロバイダー/推論時刻）を「AI解析」セクションとして表示。 | `alert.model_version`, `alert.model_provider`, `alert.model_ran_at` |
  | `app/alerts/page.tsx` フィルター | 「AI要約の有無」「感情スコア帯」「緊急度帯」など追加フィルターで実データ分析を想定。 | `alert.ai_summary`, `alert.sentiment_score`, `alert.urgency_score` |
- 実装タスク（UI側）:
  1. `types/ai.ts`（新規）でスコアレンジとラベルを管理。
  2. `lib/ai-formatters.ts`（新規）でスコア→色/テキスト変換を共通化。
  3. 各コンポーネントに新プロップを渡すよう `app/alerts/page.tsx` の `AlertCard`/`AlertDetail` 呼び出しを更新。
  4. スケルトン/ローディング時も本番指標の枠を表示し、実データを入れた際の視認性を先に検証。

### 5. 実装順序（推奨）
1. 推論クライアント抽象レイヤー + 環境変数切替の導入。
2. ローカル推論エンドポイントの PoC（OSS モデル + Docker）。
3. パイプライン/監視フローを `scripts/` と `docs/` に反映。
4. UI を本番仕様へリファインし、モック値を刷新。
5. コスト/負荷計測を行い、本番モード（API or 自前）を確定。

### 6. 設定・環境変数
- `SENTIMENT_PROVIDER`: `huggingface` / `local` を切替。デフォルトは `huggingface`。
- `HUGGINGFACE_API_KEY`: APIモード利用時のトークン。`env.example` に追加済み。
- `LOCAL_SENTIMENT_ENDPOINT`: 自前推論エンドポイントのURL（例: `http://gpu-service.internal/sentiment`）。ローカルモード時は必須。

### 7. 定常検知オペレーション
- **リアルタイム（イベント毎）**: Gmail Watch / PubSub → Cloud Run ワーカーで `sentiment_score` / `urgency_score` / `primarySegment` を即時更新。Slack などの通知トリガーもこの経路に接続。
- **日次 (毎日 06:00 JST)**:
  - `vw_alerts_scored_bq` 再計算・遷移漏れチェック
  - `incident_outcomes` 最新化、`alerts_v2_scored` へ鎮火確率・予測TTRを書き戻し
  - 集約テーブル（ダッシュボード用）を再作成
- **週次/隔週**:
  - `reply_quality` 再学習と品質スコア更新
  - 類似検索インデックス（Faiss 等）の再構築
  - 棚卸し（Precision/Recall レポート、閾値チューニング）

上記は Cloud Scheduler + Cloud Run Jobs でトリガーする想定。PoC では日次バッチで動作確認 → リアルタイムワーカーを順次追加する。

- **Precision/Recall テンプレ**: `node scripts/evaluate_detection.mjs` を実行し、`data/mock/detection_labels.json` と `data/mock/detection_predictions.json` の突合で TP/FP/FN を算出。実データ投入後も同形式のラベル・予測ペアを書き出せばそのまま評価できる。
- **Hugging Face 健全性チェック**: `HUGGINGFACE_API_KEY` を設定し `node scripts/check_sentiment_provider.mjs` を実行すると、代表テキスト2件で推論しレスポンス/スコアをログ出力。API障害時はルールベースにフォールバックしつつ、Scriptで定期監視する。
- **AI類似/推奨**: `/api/ai/similar` / `/api/ai/summary` をモックで先行実装済み。将来的に Vertex AI などへ差し替える場合も同インターフェースを利用する。

### 8. モック / プロト / 本番要件の切り分け

| 項目 | モック | プロトタイプ (PoC) | 本番要件 |
| --- | --- | --- | --- |
| データ源 | `data/mock/dummyAlerts.ts` の静的データ。件名/本文は手動入力。`/api/ai/*` もモックレスポンス | BigQuery スナップショットをマスクして投入。`scripts/sql/bq_seed_dummy_data.sql` 等で実データを準備 | Gmail Users.watch + Pub/Sub + Cloud Run でリアルタイム取り込み。`alerts_v2_scored` を本番テーブルとして利用 |
| 検知ロジック | ルール/スコアをハードコード。セグメントや検知スコアを `DUMMY_ALERTS` に埋め込み | Cloud Run/Functions でリアルタイムスコアリングし、`scripts/process_alert_transitions.ts` をステージ環境で実行 | 差分同期ワーカーで `historyId` を追跡し、`incident_outcomes` と `reply_quality` を定期計算。DLQ/冪等化まで実装 |
| モデル/AI | `/api/ai/similar` `/api/ai/summary` はモック (`data/mock/aiRecommendations.ts`) | 感情分析は Hugging Face Inference API を直接呼び、類似事例は BigQuery から抽出 | Vertex AI / 自前GPU 等の推論エンドポイントに切替。結果を BigQuery に保存して監査可能に |
| UI | 件名=最新メール件名、本文プレビューを `deriveAlertFromEmails` で生成。指標カードと AI セクションを表示 | 実データの指標 (感情/緊急度/鎮火予測/品質) を表示し、手動対応サイクルを検証 | 検知履歴・監査ログ・担当リクエストUIを備え、Ops ツールや通知と連携 |
| タイミング | フロントでダミーデータをロード | 日次バッチ＋手動トリガーで処理を検証 | リアルタイム（PubSub）、日次（ビュー更新）、週次（学習）を Cloud Scheduler/Jobs で自動化 |
| 監視/評価 | 手動確認のみ | `node scripts/evaluate_detection.mjs` で定期チェック、Slack などへ結果を共有 | Cloud Monitoring で遅延/失敗率を監視し、Precision/Recall を週次レポート化。API/APIキー監査も実施 |

## 修正が必要な可能性があるコード

### 1. `scripts/sql/bq_alert_transitions.sql`

**修正箇所**:
- 行44-48: `primary_segment` → 実際のカラム名に修正
- 行64: `alerts_v2_scored`テーブルのカラム名を確認
- 行48: `alert_id` → 実際のカラム名に修正

### 2. `scripts/process_alert_transitions.ts`

**修正箇所**:
- 行70: `alert_id` → 実際のカラム名に修正
- 行89-94: UPDATE文のカラム名を確認
- 行152: `alert_id` → 実際のカラム名に修正
- 行169-175: UPDATE文のカラム名を確認

## 実データ運用開始前の推奨手順

1. **テーブル構造の確認**
   ```bash
   # BigQueryコンソールで実行
   # 上記の確認SQLを実行してカラム名を確認
   ```

2. **SQLファイルの修正**
   ```bash
   # 確認したカラム名に合わせて修正
   # scripts/sql/bq_alert_transitions.sql
   # scripts/process_alert_transitions.ts
   ```

3. **ビューの作成**
   ```bash
   # BigQueryコンソールで実行
   # scripts/sql/bq_alert_transitions.sqlを実行
   ```

4. **テスト実行**
   ```bash
   # 本番環境のコピーでテスト実行
   npx ts-node scripts/process_alert_transitions.ts
   ```

5. **本番環境への適用**
   ```bash
   # テストが成功したら本番環境に適用
   # 定期的なバッチ処理として設定（例: Cloud Scheduler）
   ```

## 結論

### ✅ 実データで運用可能な条件

1. **テーブル構造が想定通り**: `alerts_v2_scored`テーブルに必要なカラムが存在
2. **依存テーブルが存在**: `unified_email_messages`テーブルが存在
3. **カラム名の修正**: 実データのカラム名に合わせてSQLを修正

### ⚠️ 実データ運用前に必要な作業

1. **テーブル構造の確認**: BigQueryで実際のカラム名を確認
2. **SQLファイルの修正**: 確認したカラム名に合わせて修正
3. **テスト実行**: 本番環境のコピーでテスト実行
4. **エラーハンドリングの強化**: 必要に応じてエラーハンドリングを追加

### 📝 推奨事項

- **段階的な導入**: まずは手動実行で動作確認し、問題がなければ自動化
- **監視の強化**: バッチ処理の実行結果をログに記録し、異常を検知
- **ロールバック機能**: 問題が発生した場合に元に戻せる機能を検討
