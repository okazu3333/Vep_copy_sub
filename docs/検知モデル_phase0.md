# 検知モデル フェーズ0ドキュメント


# 検知モデル フェーズ0メモ

## 必須データ

- 検知ログ（`alerts` API/DB）: アラートID、検知時刻、セグメント、スコア、要約。課題: 長文本文の閲覧権限を確認。
- メッセージ本文（メール/チャットログ）: 件名、本文、添付メタ。課題: 個人情報マスクルールの整理。
- 対応履歴（`alerts-threaded` 等）: 担当者、対応時刻、ステータス、コメント。課題: 過去分の履歴欠損補完。
- 顧客マスタ（スプレッドシート / 内部DB）: 契約状況、リスク指標、業種。課題: 最新データの手動反映プロセス整備。
- 担当者プロファイル（ユーザー管理）: 担当顧客数、役職、経験。課題: 管理者権限で一括閲覧できる設定。
- KPI 指標（ダッシュボード集計）: 対応率、平均対応時間、総アラート数。課題: モデル評価指標との紐付け。

## 管理者UI コア要件

- チーム別に担当者をグルーピングして一覧表示。
- 各メンバーの検知サマリー（件数/重大度/未対応）をひと目で把握。
- 検知詳細の要約と推奨アクション、根拠となるログ表示。
- コメント・指示送信・再通知などの行動ボタンを即時利用可能にする。
- 対応履歴・管理者メモをタイムライン形式で表示。
- 期間・検知タイプ・優先度などの基本フィルタを実装。

## 運用コスト（目安）

- ツール利用費: NLP API / 可視化ツール 1〜2 万円 / 月（必要な分だけ従量課金）。
- サーバー代: 小規模推論用 VM 2〜4 万円 / 月（プロトタイプ期間はスポット利用）。

## 検知コア機能とユースケース（現状不足項目）

### 予兆・観測レイヤー（未検討項目）

#### 1. 予兆検知（アラート前段階の兆候）
- **現状**: アラート検知のみ検討済み
- **不足**: まだアラートに至らない「予兆」段階の検知ロジック
- **必要なデータ**: 
  - メール送受信頻度の変化
  - 顧客側の返信パターン変化
  - 過去の類似ケースとの比較

#### 2. 「不安・違和感」の具体的検知
- **現状**: 感情分析（sentiment score）のみ
- **不足**: 「念のため確認ですが」のような特定言い回しの検知
- **必要なロジック**:
  - 確認系フレーズパターンマッチング
  - コミュニケーションの「不自然さ」検知
  - 過去とのトーン比較

#### 3. 「放置」状態の時間ベース検知
- **現状**: 対応時間はKPIとして言及
- **不足**: 「72時間放置で検知」のような具体的ルール定義
- **必要な実装**:
  - 最終メール時刻からの経過時間計算
  - 顧客からの未読/未返信の検知
  - アクティブなスレッドの放置検知

#### 4. 対応品質の定量化
- **現状**: 未検討
- **不足**: 返信内容の品質評価ロジック
- **必要な指標**:
  - 返信文の丁寧さスコア
  - 質問への回答率
  - 情報の正確性（後日フォローで判定）

### 検知レイヤー（不足している検知ルール）

#### 1. 「感情ダウン + 催促ワード」の組み合わせ検知
- **現状**: 感情分析とキーワード検知は個別実装
- **不足**: 組み合わせロジックの定義
- **実装要件**:
  ```
  IF (sentiment_score < -0.3) AND 
     (催促ワードマッチ) AND
     (期間内の感情トレンドが下降)
  THEN 検知トリガー
  ```

#### 2. 「72時間放置で検知」ルール
- **現状**: 時間ベース検知の具体例が未定義
- **実装要件**:
  - 最終アクティビティ時刻の取得
  - 現在時刻との差分計算
  - 72時間（可設定）閾値での検知
  - 重要度に応じた閾値調整（緊急案件は24h等）

#### 3. 「夜間返信率50%越」異常検知
- **現状**: 対応時間のみ検討、時間帯分析は未実装
- **不足**: 
  - 返信時刻の時間帯分類（夜間=22:00-6:00想定）
  - 担当者別の返信時間帯パターン分析
  - 異常値検知（通常20%が急に50%超など）
- **用途**: 過負荷・不規則勤務の検知

#### 4. 「トーンダウン + 返信頻度変化」の組み合わせ検知
- **現状**: 個別指標のみ
- **不足**: 複合パターン検知ロジック
- **実装要件**:
  ```
  - 過去30日の平均感情スコア vs 直近7日の平均
  - 過去30日の平均返信頻度 vs 直近7日の平均
  - 両方が同時に下降 → 検知トリガー
  ```

#### 5. 「催促（進捗いかがでしょ）」の具体的検知
- **現状**: 催促系キーワードは存在するが、フレーズパターンは簡易
- **不足**: より自然な催促表現の検知
  - 「進捗いかがでしょうか」
  - 「お返事いただけますでしょうか」
  - 「確認させていただきたいのですが」
- **実装**: N-gramパターン + 文脈解析

### 行動レイヤー（推奨アクションの詳細化不足）

#### 1. 「不安解消フォロー」アクション
- **現状**: 推奨アクションはLLM生成想定だが、具体的テンプレート未定義
- **不足**: 
  - 不安検知時の標準フォロー手順
  - 推奨文面のテンプレート
  - フォローアップのタイミング設定

#### 2. 「ポール（本質）明確にし、返信判断」アクション
- **現状**: LLM要約は想定済み
- **不足**: 
  - 問題の「本質（ポール）」抽出ロジック
  - 返信判断基準（返信すべき/別対応/エスカレーション）の自動判定
  - 判断根拠の可視化

#### 3. 「本質改善もしくは、リソース分配」アクション
- **現状**: 未検討（マネジメント層向けの上位判断）
- **不足**: 
  - システム的/構造的問題の検知（担当者のスキル不足 vs リソース不足）
  - リソース再分配の推奨ロジック
  - 本質改善提案の生成（プロセス改善、教育実施など）

#### 4. 「返信文や、ワードチョイスの改善」アクション
- **現状**: 推奨アクションに含まれるが、具体的フィードバック内容が未定義
- **不足**:
  - 改善前後の返信文比較
  - 具体的な改善ポイントのハイライト
  - ワードチョイスの推奨例

#### 5. 「返信フォロー」アクション
- **現状**: 基本的な対応履歴は取得可能
- **不足**:
  - 返信後の顧客反応モニタリング
  - フォローが必要なケースの自動判定
  - フォローアップタイミングの自動提案

### データ要件の追加

#### 1. 時間帯データ
- メール送受信時刻の時分秒情報（既存テーブルにありそうだが確認）
- 返信時間帯の集計用テーブル

#### 2. 返信頻度・パターン
- 担当者別の過去30日/90日の返信頻度統計
- 顧客別の期待返信頻度との比較

#### 3. トーンの時系列変化
- 過去の感情スコア履歴（30日ロールングウィンドウ）
- トレンド計算（増加/減少/横ばい）

#### 4. 対応品質指標
- 返信文の文字数、丁寧さスコア（既存NLPで計算可能）
- 質問に対する回答率
- 顧客満足度の後追いデータ（あれば）

## 直近タスク

1. 必須データの取得権限と欠損状況を確認。
2. 管理者画面のワイヤーフレーム草案を作成。
3. モデル評価指標を KPI 指標と合わせて定義。
4. **【追加】上記不足項目の検知ルール定義書作成。**
5. **【追加】時間ベース検知（72h等）の実装設計。**
6. **【追加】組み合わせ検知ロジックのプロトタイプ。**

## アーキテクチャ概要

```
flowchart LR
    subgraph DataSources[Data Sources]
        A1[Alerts API]\nA2[Message Logs]\nA3[Response History]\nA4[Customer Sheet]
    end

    subgraph Ingestion[Ingestion & ETL]
        B1[ETL Script (cron/Airflow)]
        B2[Data Validation]
    end

    subgraph Storage[Storage]
        C1[Raw Data Bucket]
        C2[Feature Store/SQLite]
    end

    subgraph Processing[Processing]
        D1[Text Cleaning]
        D2[Embedding Generation]
        D3[Feature Engineering]
    end

    subgraph Modeling[Modeling]
        E1[Rule Engine]
        E2[Anomaly Detector]
        E3[LLM Summarizer]
    end

    subgraph Serving[Serving]
        F1[Batch Scoring]
        F2[FastAPI Inference]
        F3[Result Store]
    end

    subgraph UI[Interfaces]
        G1[Admin Dashboard]
        G2[Notifier/Tasks]
    end

    DataSources --> Ingestion --> Storage --> Processing --> Modeling --> Serving --> UI
    Serving -->|Metrics| Monitoring
    Monitoring[(Monitoring/Logs)] --> UI
```

### 補足
- `ETL Script` は Python バッチで各データソースを取得し、S3 互換ストレージと SQLite/PostgreSQL に格納。
- `Embedding Generation` は Hugging Face API などを利用し、ローカルでキャッシュ。
- `Rule Engine` と `Anomaly Detector` の出力を統合し、`LLM Summarizer` で要約と推奨アクションを生成。
- `FastAPI Inference` は即時判定用エンドポイント。バッチ結果は `Result Store` を通じて管理者 UI と通知に連携。
- `Monitoring` はログ集約とスコア分布のウォッチを担当。

---

更新履歴
- 2025-10-24 初稿作成 / ソロ開発向けに縮約
- 2025-10-24 アーキテクチャ図追加

